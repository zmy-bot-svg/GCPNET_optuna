#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿæµ‹è¯•è„šæœ¬
åœ¨ç§ŸæœåŠ¡å™¨ä¹‹å‰æµ‹è¯•é…ç½®æ˜¯å¦æ­£ç¡®
"""

import os
import sys
import time
from utils.flags import Flags

def test_config_loading():
    """æµ‹è¯•é…ç½®æ–‡ä»¶åŠ è½½"""
    print("ğŸ”§ æµ‹è¯•é…ç½®æ–‡ä»¶åŠ è½½...")
    try:
        flags = Flags()
        config = flags.updated_config
        print(f"âœ… é…ç½®åŠ è½½æˆåŠŸ")
        print(f"   Project: {config.project_name}")
        print(f"   Dataset: {config.dataset_name}")
        print(f"   Batch size: {config.batch_size}")
        print(f"   Hidden features: {config.hidden_features}")
        return config
    except Exception as e:
        print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
        return None

def test_dataset_loading(config):
    """æµ‹è¯•æ•°æ®é›†åŠ è½½"""
    print("\nğŸ“Š æµ‹è¯•æ•°æ®é›†åŠ è½½...")
    try:
        from main import setup_dataset
        dataset = setup_dataset(config)
        print(f"âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ")
        print(f"   æ•°æ®ç‚¹æ•°é‡: {len(dataset)}")
        print(f"   æ•°æ®é›†è·¯å¾„: {config.dataset_path}")
        return True
    except Exception as e:
        print(f"âŒ æ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
        print("   è¯·æ£€æŸ¥æ•°æ®é›†è·¯å¾„æ˜¯å¦æ­£ç¡®")
        return False

def test_model_creation(config):
    """æµ‹è¯•æ¨¡å‹åˆ›å»º"""
    print("\nğŸ§  æµ‹è¯•æ¨¡å‹åˆ›å»º...")
    try:
        from main import setup_dataset, setup_model
        import torch
        
        dataset = setup_dataset(config)
        net = setup_model(dataset, config)
        
        # è®¡ç®—æ¨¡å‹å‚æ•°æ•°é‡
        total_params = sum(p.numel() for p in net.parameters())
        trainable_params = sum(p.numel() for p in net.parameters() if p.requires_grad)
        
        print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        print(f"   æ€»å‚æ•°: {total_params:,}")
        print(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        print(f"   éšè—ç‰¹å¾ç»´åº¦: {config.hidden_features}")
        
        # æµ‹è¯•GPUæ˜¯å¦å¯ç”¨
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
            print(f"   GPU: {gpu_name} ({gpu_memory:.1f}GB)")
        else:
            print("   âš ï¸  è­¦å‘Š: GPUä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU")
        
        return True
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return False

def test_optuna_setup():
    """æµ‹è¯•Optunaè®¾ç½®"""
    print("\nğŸ”¬ æµ‹è¯•Optunaè®¾ç½®...")
    try:
        import optuna
        from optuna.integration import TensorBoardCallback
        
        # åˆ›å»ºä¸´æ—¶studyæµ‹è¯•
        study = optuna.create_study(direction="minimize")
        print(f"âœ… Optunaè®¾ç½®æ­£å¸¸")
        print(f"   Optunaç‰ˆæœ¬: {optuna.__version__}")
        return True
    except Exception as e:
        print(f"âŒ Optunaè®¾ç½®å¤±è´¥: {e}")
        print("   è¯·è¿è¡Œ: pip install optuna optuna-integration")
        return False

def estimate_training_time(config):
    """ä¼°ç®—è®­ç»ƒæ—¶é—´"""
    print("\nâ±ï¸  ä¼°ç®—è®­ç»ƒæ—¶é—´...")
    
    # åŸºäºç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼šRTX 4060 8åˆ†é’Ÿ/epoch
    base_time_per_epoch = 8  # åˆ†é’Ÿ (RTX 4060)
    
    if "4090" in config.project_name:
        # RTX 4090å¤§çº¦æ¯”4060å¿«4-5å€
        time_per_epoch = base_time_per_epoch / 4.5
        gpu_type = "RTX 4090"
    else:
        time_per_epoch = base_time_per_epoch
        gpu_type = "RTX 4060"
    
    epochs_per_trial = config.epochs
    num_trials = config.sweep_count
    
    total_epochs = epochs_per_trial * num_trials
    total_time_minutes = total_epochs * time_per_epoch
    total_time_hours = total_time_minutes / 60
    
    print(f"   GPUç±»å‹: {gpu_type}")
    print(f"   æ¯epochæ—¶é—´: {time_per_epoch:.1f}åˆ†é’Ÿ")
    print(f"   è¯•éªŒæ¬¡æ•°: {num_trials}")
    print(f"   æ¯è¯•éªŒepochæ•°: {epochs_per_trial}")
    print(f"   æ€»è®¡æ—¶é—´: {total_time_hours:.1f}å°æ—¶")
    
    if "4090" in config.project_name:
        cost = total_time_hours * 2  # 2å…ƒ/å°æ—¶
        print(f"   é¢„è®¡æˆæœ¬: {cost:.0f}å…ƒ")
    
    return total_time_hours

def main():
    print("ğŸš€ GCPNet å¿«é€Ÿæµ‹è¯•")
    print("="*50)
    
    # æ£€æµ‹é…ç½®æ–‡ä»¶
    config_file = "./config.yml"
    if "4090" in sys.argv:
        config_file = "./config_4090.yml"
        print("ğŸ“ ä½¿ç”¨4090ä¼˜åŒ–é…ç½®")
    
    if not os.path.exists(config_file):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        sys.exit(1)
    
    # è¿è¡Œæµ‹è¯•
    config = test_config_loading()
    if not config:
        sys.exit(1)
    
    if not test_dataset_loading(config):
        sys.exit(1)
    
    if not test_model_creation(config):
        sys.exit(1)
    
    if not test_optuna_setup():
        sys.exit(1)
    
    # ä¼°ç®—æ—¶é—´
    estimated_hours = estimate_training_time(config)
    
    print("\n" + "="*50)
    print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    print("\nğŸ’¡ å»ºè®®:")
    if estimated_hours > 20:
        print("   - æ¨èä½¿ç”¨RTX 4090æœåŠ¡å™¨")
        print("   - ä½¿ç”¨config_4090.ymlé…ç½®")
    else:
        print("   - å¯ä»¥åœ¨æœ¬åœ°è¿è¡Œ")
    
    print("\nğŸš€ å¯åŠ¨è¶…å‚æ•°æœç´¢:")
    if "4090" in config_file:
        print("   python main.py --config_file config_4090.yml --task_type hyperparameter")
    else:
        print("   python main.py --config_file config.yml --task_type hyperparameter")

if __name__ == "__main__":
    main()