#!/usr/bin/python
# -*- encoding: utf-8 -*-

# å¯¼å…¥å¿…è¦çš„åº“ç”¨äºæ—¶é—´å¤„ç†ã€æ“ä½œç³»ç»Ÿäº¤äº’å’Œæ—¶é—´è®¡ç®—
import datetime
import os
import time
import copy  # æ–°å¢ï¼šç”¨äºæ·±æ‹·è´é…ç½®

# å¯¼å…¥PyTorchç›¸å…³åº“ç”¨äºæ·±åº¦å­¦ä¹ æ¨¡å‹æ„å»ºå’Œè®­ç»ƒ
import torch
import wandb  # ç”¨äºå®éªŒè·Ÿè¸ªå’Œå¯è§†åŒ–
import torch.nn as nn
import torchmetrics  # ç”¨äºè®¡ç®—å„ç§è¯„ä¼°æŒ‡æ ‡
from torch_geometric.transforms import Compose  # ç”¨äºç»„åˆå¤šä¸ªæ•°æ®å˜æ¢

# æ–°å¢ï¼šå¯¼å…¥ Optuna
import optuna
import optuna.exceptions  # æ–°å¢ï¼šç”¨äºå‰ªæå¼‚å¸¸å¤„ç†
from optuna.integration import TensorBoardCallback
import tensorboard

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from model import GCPNet  # GCPNetæ¨¡å‹çš„ä¸»è¦å®ç°
from utils.keras_callbacks import WandbCallback  # Wandbå›è°ƒå‡½æ•°
from utils.dataset_utils import MP18, dataset_split, get_dataloader  # æ•°æ®é›†å¤„ç†å·¥å…·
from utils.flags import Flags  # é…ç½®å‚æ•°ç®¡ç†
from utils.train_utils import KerasModel, LRScheduler  # è®­ç»ƒå·¥å…·å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨
from utils.transforms import GetAngle, ToFloat  # æ•°æ®å˜æ¢å·¥å…·

# è®¾ç½®NumExpråº“çš„æœ€å¤§çº¿ç¨‹æ•°ä¸º24ï¼Œç”¨äºåŠ é€Ÿæ•°å€¼è®¡ç®—
os.environ["NUMEXPR_MAX_THREADS"] = "24"
# å¼€å¯è°ƒè¯•æ¨¡å¼ï¼Œç”¨äºæ‰“å°è°ƒè¯•ä¿¡æ¯
debug = True 

# å¯¼å…¥æ—¥å¿—ç›¸å…³åº“
import logging
from logging.handlers import RotatingFileHandler

# æ–°å¢ï¼šæ˜¾å­˜ç®¡ç†å·¥å…·
import gc
import time

class GPUMemoryManager:
    def __init__(self, verbose=True):
        self.verbose = verbose
    
    def get_memory_info(self):
        if not torch.cuda.is_available():
            return {"total": 0, "allocated": 0, "cached": 0, "free": 0}
        
        total = torch.cuda.get_device_properties(0).total_memory / 1e9
        allocated = torch.cuda.memory_allocated() / 1e9
        cached = torch.cuda.memory_reserved() / 1e9
        free = total - cached
        
        
        return {"total": total, "allocated": allocated, "cached": cached, "free": free}
    
    def safe_cleanup(self, force=False):
        if not torch.cuda.is_available():
            return
        
        before = self.get_memory_info()
        gc.collect()
        torch.cuda.empty_cache()
        
        if force:
            torch.cuda.synchronize()
            time.sleep(0.1)
            torch.cuda.empty_cache()
        
        after = self.get_memory_info()
        if self.verbose:
            freed = before['cached'] - after['cached']
            if freed > 0.1:
                print(f"ğŸ§¹ Cleaned {freed:.2f}GB GPU memory")

# é…ç½®æ—¥å¿—ç³»ç»Ÿï¼Œç”¨äºè®°å½•è®­ç»ƒè¿‡ç¨‹ä¸­çš„é‡è¦ä¿¡æ¯
def log_config(log_file='test.log'):
    # å®šä¹‰æ—¥å¿—æ ¼å¼ï¼š[æ—¶é—´æˆ³][æ—¥å¿—çº§åˆ«]: æ¶ˆæ¯å†…å®¹
    LOG_FORMAT = '[%(asctime)s][%(levelname)s]: %(message)s'
    # è®¾ç½®æ—¥å¿—çº§åˆ«ä¸ºINFOï¼Œè®°å½•é‡è¦çš„è®­ç»ƒä¿¡æ¯
    level = logging.INFO
    # é…ç½®åŸºç¡€æ—¥å¿—è®¾ç½®
    logging.basicConfig(level=level, format=LOG_FORMAT)
    # åˆ›å»ºæ–‡ä»¶æ—¥å¿—å¤„ç†å™¨ï¼Œæ”¯æŒæ—¥å¿—è½®è½¬ï¼ˆæœ€å¤§2MBï¼Œä¿ç•™3ä¸ªå¤‡ä»½æ–‡ä»¶ï¼‰
    log_file_handler = RotatingFileHandler(filename=log_file, maxBytes=2*1024*1024, backupCount=3)
    # è®¾ç½®æ—¥å¿—æ ¼å¼åŒ–å™¨
    formatter = logging.Formatter(LOG_FORMAT)
    log_file_handler.setFormatter(formatter)
    # å°†æ–‡ä»¶å¤„ç†å™¨æ·»åŠ åˆ°æ ¹æ—¥å¿—è®°å½•å™¨
    logging.getLogger('').addHandler(log_file_handler)

# è®¾ç½®éšæœºç§å­ï¼Œç¡®ä¿å®éªŒçš„å¯é‡å¤æ€§
def set_seed(seed):
    # å¯¼å…¥éšæœºæ•°ç”Ÿæˆç›¸å…³åº“
    import random
    import numpy as np
    # è®¾ç½®PythonåŸç”Ÿrandomæ¨¡å—çš„éšæœºç§å­
    random.seed(seed)
    # è®¾ç½®NumPyçš„éšæœºç§å­
    np.random.seed(seed)
    # è®¾ç½®PyTorch CPUæ“ä½œçš„éšæœºç§å­
    torch.manual_seed(seed)
    # è®¾ç½®PyTorch GPUæ“ä½œçš„éšæœºç§å­ï¼ˆé€‚ç”¨äºæ‰€æœ‰GPUï¼‰
    torch.cuda.manual_seed_all(seed)
    # å¯ç”¨ç¡®å®šæ€§ç®—æ³•ï¼Œç¡®ä¿GPUè®¡ç®—ç»“æœå¯é‡å¤
    torch.backends.cudnn.deterministic = True
    # ç¦ç”¨cudnnçš„benchmarkæ¨¡å¼ï¼Œè™½ç„¶å¯èƒ½å½±å“æ€§èƒ½ä½†ä¿è¯ç»“æœä¸€è‡´
    torch.backends.cudnn.benchmark = False

# è®¾ç½®å’Œåˆå§‹åŒ–æ•°æ®é›†ï¼Œè¿™æ˜¯GCPNetè®­ç»ƒçš„ç¬¬ä¸€æ­¥
def setup_dataset(config):
    dataset = MP18(root=config.dataset_path, name=config.dataset_name, transform=Compose([GetAngle(), ToFloat(
        )]), r=config.max_edge_distance, n_neighbors=config.n_neighbors, edge_steps=config.edge_input_features, image_selfloop=True, points=config.points, target_name=config.target_name)
    return dataset

# åˆå§‹åŒ–GCPNetæ¨¡å‹ï¼Œé…ç½®æ¨¡å‹çš„å„ç§è¶…å‚æ•°
def setup_model(dataset, config):
    net = GCPNet(
            data=dataset,
            firstUpdateLayers=config.firstUpdateLayers,
            secondUpdateLayers=config.secondUpdateLayers,
            atom_input_features=config.atom_input_features,
            edge_input_features=config.edge_input_features,
            triplet_input_features=config.triplet_input_features,
            embedding_features=config.embedding_features,
            hidden_features=config.hidden_features,
            output_features=config.output_features,
            min_edge_distance=config.min_edge_distance,
            max_edge_distance=config.max_edge_distance,
            link=config.link,
            dropout_rate=config.dropout_rate,
        )
    return net

# è®¾ç½®ä¼˜åŒ–å™¨ï¼Œç”¨äºæ¨¡å‹å‚æ•°çš„æ›´æ–°
def setup_optimizer(net, config):
    optimizer = getattr(torch.optim, config.optimizer)(
        net.parameters(),
        lr=config.lr,
        **config.optimizer_args
    )
    if config.debug:
        print(f"optimizer: {optimizer}")
    return optimizer

# è®¾ç½®å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œç”¨äºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡
def setup_schduler(optimizer, config):
    scheduler = LRScheduler(optimizer, config.scheduler, config.scheduler_args)
    return scheduler

# æ„å»ºKerasé£æ ¼çš„æ¨¡å‹åŒ…è£…å™¨ï¼Œç®€åŒ–è®­ç»ƒæµç¨‹
def build_keras(net, optimizer, scheduler):
    model = KerasModel(
        net=net,
        loss_fn=nn.L1Loss(),
        metrics_dict={
            "mae": torchmetrics.MeanAbsoluteError(),
            "mape": torchmetrics.MeanAbsolutePercentageError()
        }, 
        optimizer=optimizer,
        lr_scheduler=scheduler
    )
    return model

# ä¸»è¦çš„è®­ç»ƒå‡½æ•°ï¼Œæ‰§è¡Œå®Œæ•´çš„æ¨¡å‹è®­ç»ƒæµç¨‹
def train(config, printnet=False, trial=None):  # æ–°å¢trialå‚æ•°ç”¨äºå‰ªæ
    name = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # å¦‚æœå¯ç”¨äº†wandbæ—¥å¿—è®°å½•ï¼Œåˆå§‹åŒ–Weights & Biaseså®éªŒè·Ÿè¸ª
    if config.log_enable:
        wandb.init(project=config.project_name, name=name, save_code=False)

    # ç¬¬1æ­¥ï¼šåŠ è½½å’Œå‡†å¤‡æ•°æ®
    dataset = setup_dataset(config)
    train_dataset, val_dataset, test_dataset = dataset_split(
        dataset, train_size=0.8, valid_size=0.1, test_size=0.1, seed=config.seed, debug=debug) 
    train_loader, val_loader, test_loader = get_dataloader(
        train_dataset, val_dataset, test_dataset, config.batch_size, config.num_workers)

    # ç¬¬2æ­¥ï¼šåŠ è½½å’Œåˆå§‹åŒ–ç½‘ç»œæ¨¡å‹
    rank = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    net = setup_model(dataset, config).to(rank)
    if config.debug and printnet:
        print(net)

    # ç¬¬3æ­¥ï¼šè®¾ç½®ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨
    optimizer = setup_optimizer(net, config)
    scheduler = setup_schduler(optimizer, config)

    # ç¬¬4æ­¥ï¼šå¼€å§‹è®­ç»ƒè¿‡ç¨‹
    if config.log_enable:
        callbacks = [WandbCallback(project=config.project_name, config=config)]
    else:
        callbacks = None
    
    model = build_keras(net, optimizer, scheduler)
    
    # å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼ˆä¼ é€’trialç”¨äºå‰ªæï¼‰
    history = model.fit(
        train_loader,
        val_loader,
        ckpt_path=os.path.join(config.output_dir, config.net+'.pth'),
        epochs=config.epochs,
        monitor='val_loss',
        mode='min',
        patience=config.patience,
        plot=True,
        callbacks=callbacks,
        trial=trial  # æ–°å¢ï¼šä¼ é€’trialå¯¹è±¡ç”¨äºå‰ªæ
    )
    
    # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½
    test_result = model.evaluate(test_loader)
    print(test_result)
    
    # å¦‚æœå¯ç”¨æ—¥å¿—è®°å½•ï¼Œè®°å½•æœ€ç»ˆçš„æµ‹è¯•ç»“æœ
    if config.log_enable:
        wandb.log({
            "test_mae": test_result['val_mae'],
            "test_mape": test_result['val_mape'],
            "total_params": model.total_params()
        })
        wandb.finish()

    # è¿”å›è®­ç»ƒå†å²å’Œæœ€ä½³éªŒè¯è¯¯å·®
    best_val_mae = min(history['val_mae']) if 'val_mae' in history else float('inf')
    return best_val_mae

# æ–°å¢ï¼šOptuna è¶…å‚æ•°æœç´¢çš„ç›®æ ‡å‡½æ•°
def objective(trial, base_config):
    """
    Optuna ä¼˜åŒ–çš„ç›®æ ‡å‡½æ•°
    
    Args:
        trial: Optuna trial å¯¹è±¡
        base_config: åŸºç¡€é…ç½®å¯¹è±¡
    
    Returns:
        float: è¦æœ€å°åŒ–çš„ç›®æ ‡å€¼ï¼ˆéªŒè¯é›† MAEï¼‰
    """
    # æ·±æ‹·è´é…ç½®ä»¥é¿å…ä¿®æ”¹åŸå§‹é…ç½®
    config = copy.deepcopy(base_config)
    
    # ä¼˜åŒ–åçš„è¶…å‚æ•°æœç´¢ç©ºé—´ï¼ˆæ›´èšç„¦åœ¨ä½ ä¹‹å‰æ•ˆæœå¥½çš„åŒºåŸŸï¼‰
    # å­¦ä¹ ç‡ï¼šä»¥ä½ ä¹‹å‰å¥½çš„0.001ä¸ºä¸­å¿ƒï¼Œé€‚å½“æ‰©å¤§èŒƒå›´
    config.lr = trial.suggest_float("lr", 0.0005, 0.002, log=True)
    
    # Dropoutï¼šé™ä½ä¸Šé™ï¼Œé¿å…è¿‡é«˜çš„dropoutå½±å“å­¦ä¹ 
    config.dropout_rate = trial.suggest_float("dropout_rate", 0.05, 0.2)  # é™ä½ä¸Šé™ä»0.3åˆ°0.2
    
    # weight_decayï¼šé€‚ä¸­èŒƒå›´
    weight_decay = trial.suggest_float("weight_decay", 1e-5, 1e-4, log=True)  # é™ä½ä¸Šé™
    config.optimizer_args = config.optimizer_args.copy()
    config.optimizer_args['weight_decay'] = weight_decay
    
    # ç½‘ç»œå±‚æ•°ï¼šä¿æŒåŸèŒƒå›´
    config.firstUpdateLayers = trial.suggest_categorical("firstUpdateLayers", [3, 4, 5])
    config.secondUpdateLayers = trial.suggest_categorical("secondUpdateLayers", [3, 4, 5])
    
    # éšè—å±‚ç»´åº¦ï¼šæ›´å€¾å‘äºå¤§æ¨¡å‹ï¼Œå¢åŠ 256é€‰é¡¹
    config.hidden_features = trial.suggest_categorical("hidden_features", [96, 128, 160])  # å¢åŠ 160é€‰é¡¹
    
    # ========================================================== #
    # ğŸš€ æ¸…æ™°æ˜¾ç¤ºå½“å‰è¯•éªŒçš„è¶…å‚æ•°
    # ========================================================== #
    print("\n" + "="*60)
    print(f"ğŸš€ Starting Trial #{trial.number}")
    print("  Parameters:")
    for key, value in trial.params.items():
        print(f"    - {key}: {value}")
    print("="*60 + "\n")
    # ========================================================== #
    
    # å…³é—­ wandb æ—¥å¿—ï¼ˆç”± Optuna ç®¡ç†ï¼‰
    config.log_enable = False
    
    # ä¸ºæ¯ä¸ª trial åˆ›å»ºå”¯ä¸€çš„è¾“å‡ºç›®å½•
    trial_name = f"trial_{trial.number}"
    config.output_dir = os.path.join(base_config.output_dir, trial_name)
    if not os.path.exists(config.output_dir):
        os.makedirs(config.output_dir)
    
    # æ‰§è¡Œè®­ç»ƒå¹¶è¿”å›æœ€ä½³éªŒè¯ MAE
    try:
        # æ¸…ç†GPUå†…å­˜ï¼Œç¡®ä¿æ¯ä¸ªtrialå¼€å§‹æ—¶å†…å­˜å……è¶³
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            
        best_val_mae = train(config, printnet=False, trial=trial)  # ä¼ é€’trialå¯¹è±¡ç”¨äºå‰ªæ
        
        # è®­ç»ƒå®Œæˆåæ˜¾ç¤ºç»“æœ
        print(f"\nğŸ Trial #{trial.number} completed!")
        print(f"   Result: {best_val_mae:.6f}")
        print(f"   Current best: {trial.study.best_value:.6f}" if trial.study.best_value else "   First trial")
        
        # æ˜¾ç¤ºGPUå†…å­˜ä½¿ç”¨æƒ…å†µ
        if torch.cuda.is_available():
            memory_allocated = torch.cuda.memory_allocated() / 1e9
            memory_cached = torch.cuda.memory_reserved() / 1e9
            print(f"   GPU Memory: {memory_allocated:.2f}GB allocated, {memory_cached:.2f}GB cached")
        
        print("="*60)
        
        return best_val_mae
    except optuna.exceptions.TrialPruned:
        # å¤„ç†å‰ªæå¼‚å¸¸
        print(f"\nâœ‚ï¸  Trial #{trial.number} pruned!")
        print(f"   Reason: Performance not promising, stopped early")
        
        # æ¸…ç†GPUå†…å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        print("="*60)
        raise  # é‡æ–°æŠ›å‡ºï¼Œè®©Optunaå¤„ç†
    except torch.cuda.OutOfMemoryError as e:
        # å¤„ç†GPUå†…å­˜ä¸è¶³
        print(f"\nğŸ’¥ Trial #{trial.number} failed: GPU Out of Memory")
        print(f"   å»ºè®®ï¼šå‡å°‘batch_sizeæˆ–hidden_features")
        
        # å¼ºåˆ¶æ¸…ç†GPUå†…å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        print("="*60)
        return float('inf')  # è¿”å›ä¸€ä¸ªå¾ˆå¤§çš„å€¼è¡¨ç¤ºå¤±è´¥
    except Exception as e:
        print(f"âŒ Trial {trial.number} failed with error: {e}")
        
        # æ¸…ç†GPUå†…å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        print("="*60)
        return float('inf')  # è¿”å›ä¸€ä¸ªå¾ˆå¤§çš„å€¼è¡¨ç¤ºå¤±è´¥

# 4090ä¼˜åŒ–çš„è¶…å‚æ•°æœç´¢ç›®æ ‡å‡½æ•°
def objective_4090(trial, base_config):
    gpu_manager = GPUMemoryManager(verbose=True)
    config = copy.deepcopy(base_config)
    # ğŸ” æ·»åŠ è¯¦ç»†è¯Šæ–­
    print(f"\nğŸ” Trial #{trial.number} - è¯¦ç»†æ˜¾å­˜è¯Šæ–­:")
    if torch.cuda.is_available():
        total = torch.cuda.get_device_properties(0).total_memory / 1e9
        allocated = torch.cuda.memory_allocated() / 1e9
        cached = torch.cuda.memory_reserved() / 1e9
        free = total - cached
        print(f"   GPUæ€»æ˜¾å­˜: {total:.2f}GB")
        print(f"   å·²åˆ†é…: {allocated:.2f}GB") 
        print(f"   å·²ç¼“å­˜: {cached:.2f}GB")
        print(f"   å¯ç”¨: {free:.2f}GB")
        
        # å¼ºåˆ¶æ¸…ç†
        import gc
        gc.collect()
        torch.cuda.empty_cache()
        
        # æ¸…ç†åå†æ£€æŸ¥
        allocated_after = torch.cuda.memory_allocated() / 1e9
        cached_after = torch.cuda.memory_reserved() / 1e9
        free_after = total - cached_after
        print(f"   æ¸…ç†å-å·²åˆ†é…: {allocated_after:.2f}GB")
        print(f"   æ¸…ç†å-å·²ç¼“å­˜: {cached_after:.2f}GB")  
        print(f"   æ¸…ç†å-å¯ç”¨: {free_after:.2f}GB")
        
        if free_after < 10.0:  # å¦‚æœå¯ç”¨æ˜¾å­˜å°‘äº10GBå°±æœ‰é—®é¢˜
            print(f"   âš ï¸ è­¦å‘Šï¼šå¯ç”¨æ˜¾å­˜è¿‡å°‘ï¼")
            
    try:
        # è¯•éªŒå¼€å§‹å‰æ¸…ç†æ˜¾å­˜
        gpu_manager.safe_cleanup(force=False)
        
        # æ›´ä¿å®ˆçš„è¶…å‚æ•°èŒƒå›´
        config.lr = trial.suggest_float("lr", 0.0005, 0.002, log=True)
        config.dropout_rate = trial.suggest_float("dropout_rate", 0.05, 0.18)
        
        weight_decay = trial.suggest_float("weight_decay", 1e-5, 8e-5, log=True)
        config.optimizer_args = config.optimizer_args.copy()
        config.optimizer_args['weight_decay'] = weight_decay
        
        config.firstUpdateLayers = trial.suggest_categorical("firstUpdateLayers", [3, 4, 5])
        config.secondUpdateLayers = trial.suggest_categorical("secondUpdateLayers", [3, 4, 5])
        
        # ğŸ”§ æ›´å®‰å…¨çš„å‚æ•°èŒƒå›´
        config.hidden_features = trial.suggest_categorical("hidden_features", [96, 128, 160])  # ç§»é™¤192, 224
        config.batch_size = trial.suggest_categorical("batch_size", [48, 64, 96])  # ç§»é™¤128, 160
        
        print("\n" + "="*60)
        print(f"ğŸš€ Starting Trial #{trial.number} (Memory Safe)")
        print("  Parameters:")
        for key, value in trial.params.items():
            print(f"    - {key}: {value}")
        print("="*60 + "\n")
        
        config.log_enable = False
        trial_name = f"trial_{trial.number}"
        config.output_dir = os.path.join(base_config.output_dir, trial_name)
        if not os.path.exists(config.output_dir):
            os.makedirs(config.output_dir)
        
        best_val_mae = train(config,  trial=trial)
        
        print(f"\nğŸ Trial #{trial.number} completed!")
        print(f"   Result: {best_val_mae:.6f}")
        print(f"   Current best: {trial.study.best_value:.6f}" if trial.study.best_value else "   First trial")
        
        return best_val_mae
        
    except optuna.exceptions.TrialPruned:
        print(f"\nâœ‚ï¸  Trial #{trial.number} pruned!")
        gpu_manager.safe_cleanup(force=True)
        raise
        
    except torch.cuda.OutOfMemoryError as e:
        print(f"\nğŸ’¥ Trial #{trial.number} - GPU OOM")
        print(f"   é…ç½®ï¼šbatch_size={config.batch_size}, hidden_features={config.hidden_features}")
        gpu_manager.safe_cleanup(force=True)
        return float('inf')
        
    except Exception as e:
        print(f"âŒ Trial {trial.number} failed: {e}")
        gpu_manager.safe_cleanup(force=True)
        return float('inf')
        
    finally:
        gpu_manager.safe_cleanup(force=False)
        print("="*60)

# äº¤å‰éªŒè¯è®­ç»ƒå‡½æ•°ï¼Œç”¨äºæ›´å¯é çš„æ¨¡å‹æ€§èƒ½è¯„ä¼°
def train_CV(config):
    from utils.dataset_utils_strong import loader_setup_CV, split_data_CV
    dataset = setup_dataset(config)
    cv_dataset = split_data_CV(dataset, num_folds=config.num_folds, seed=config.seed)
    cv_error = []

    for index in range(0, len(cv_dataset)):
        if not(os.path.exists(output_dir := f"{config.output_dir}/{index}")):
            os.makedirs(output_dir)

        train_loader, test_loader, train_dataset, _ = loader_setup_CV(
            index, config.batch_size, cv_dataset, num_workers=config.num_workers
        )
        
        rank = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        net = setup_model(dataset, config).to(rank)
        
        optimizer = setup_optimizer(net, config)
        scheduler = setup_schduler(optimizer, config)

        model = build_keras(net, optimizer, scheduler)
        model.fit(
            train_loader, 
            None,
            ckpt_path=os.path.join(output_dir, config.net+'.pth'), 
            epochs=config.epochs,
            monitor='train_loss',
            mode='min', 
            patience=config.patience, 
            plot=True
        )

        test_error = model.evaluate(test_loader)['val_mae']
        logging.info("fold: {:d}, Test Error: {:.5f}".format(index+1, test_error)) 
        cv_error.append(test_error)
    
    import numpy as np
    mean_error = np.array(cv_error).mean()
    std_error = np.array(cv_error).std()
    logging.info("CV Error: {:.5f}, std Error: {:.5f}".format(mean_error, std_error))
    return cv_error

# é¢„æµ‹å‡½æ•°ï¼Œç”¨äºåœ¨æ–°æ•°æ®ä¸Šè¿›è¡Œæ¨ç†
def predict(config):
    dataset = setup_dataset(config)
    from torch_geometric.loader import DataLoader
    test_loader = DataLoader(dataset, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers, pin_memory=False,)

    rank = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    net = setup_model(dataset, config).to(rank)

    optimizer = setup_optimizer(net, config)
    scheduler = setup_schduler(optimizer, config)

    model = build_keras(net, optimizer, scheduler)
    model.predict(test_loader, ckpt_path=config.model_path, test_out_path=config.output_path)

# å¯è§†åŒ–å‡½æ•°ï¼Œç”¨äºåˆ†æå’Œå¯è§†åŒ–æ¨¡å‹çš„ç‰¹å¾è¡¨ç¤º
def visualize(config):
    from utils.dataset_utils_strong import MP18, dataset_split, get_dataloader
    from utils.transforms import GetAngle, ToFloat

    dataset = MP18(root=config.dataset_path,name=config.dataset_name,transform=Compose([GetAngle(),ToFloat()]), r=config.max_edge_distance, n_neighbors=config.n_neighbors, edge_steps=config.edge_input_features, image_selfloop=True,points=config.points,target_name=config.target_name)

    train_dataset, val_dataset, test_dataset = dataset_split(dataset,train_size=0.8,valid_size=0.1,test_size=0.1,seed=config.seed, debug=debug)
    train_loader, val_loader, test_loader = get_dataloader(train_dataset, val_dataset, test_dataset, config.batch_size, config.num_workers)

    rank = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    net = setup_model(dataset, config).to(rank)

    optimizer = setup_optimizer(net, config)
    scheduler = setup_schduler(optimizer, config)
    print("optimizer:",optimizer)

    model = KerasModel(net=net, loss_fn=nn.L1Loss(), metrics_dict={"mae":torchmetrics.MeanAbsoluteError(),"mape":torchmetrics.MeanAbsolutePercentageError()},optimizer=optimizer,lr_scheduler = scheduler)
    data_loader, _, _ = get_dataloader(dataset, val_dataset, test_dataset, config.batch_size, config.num_workers)
   
    model.analysis(net_name=config.net, test_data=data_loader,ckpt_path=config.model_path,tsne_args=config.visualize_args)

    return model

# ä¸»ç¨‹åºå…¥å£ç‚¹ï¼Œç¨‹åºä»è¿™é‡Œå¼€å§‹æ‰§è¡Œ
if __name__ == "__main__":

    # å¿½ç•¥PyTorchçš„TypedStorageåºŸå¼ƒè­¦å‘Šï¼Œä¸ºäº†é¿å…åœ¨ä½¿ç”¨æ—§ç‰ˆæœ¬PyTorchæ—¶å‡ºç°è­¦å‘Šä¿¡æ¯
    import warnings
    warnings.filterwarnings('ignore', '.*TypedStorage is deprecated.*')
    
    # åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨ï¼ŒåŠ è½½æ‰€æœ‰é…ç½®å‚æ•°
    flags = Flags()
    config = flags.updated_config
    
    # ç”ŸæˆåŸºäºæ—¶é—´çš„å”¯ä¸€è¾“å‡ºç›®å½•åç§°
    name = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
    config.output_dir = os.path.join(config.output_dir, name)
    if not(os.path.exists(config.output_dir)):
        os.makedirs(config.output_dir)
    set_seed(config.seed)

    # æ ¹æ®é…ç½®çš„ä»»åŠ¡ç±»å‹æ‰§è¡Œç›¸åº”çš„æ“ä½œ
    if config.task_type.lower() == 'train':
        train(config)
    
    # ä¿®æ”¹åçš„è¶…å‚æ•°æœç´¢æ¨¡å¼ï¼šä½¿ç”¨ Optuna æ›¿ä»£ Wandb
    # ä¿®å¤åçš„è¶…å‚æ•°æœç´¢éƒ¨åˆ† - æ›¿æ¢åŸæ¥çš„elif block
    elif config.task_type.lower() == 'hyperparameter':
        print("Starting Optuna hyperparameter optimization...")
        
        # ğŸ”§ ç¬¬ä¸€æ­¥ï¼šå¤„ç†æ•°æ®åº“å­˜å‚¨
        try:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(config.output_dir, exist_ok=True)
            
            # åˆ›å»ºå”¯ä¸€çš„æ•°æ®åº“æ–‡ä»¶å
            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
            db_name = f"{config.project_name}_{timestamp}.db"
            db_path = os.path.abspath(os.path.join(config.output_dir, db_name))
            
            # å¤„ç†Windowsè·¯å¾„é—®é¢˜
            if os.name == 'nt':  # Windows
                storage_url = f"sqlite:///{db_path.replace(os.sep, '/')}"
            else:
                storage_url = f"sqlite:///{db_path}"
            
            print(f"ğŸ“ æ•°æ®åº“è·¯å¾„: {db_path}")
            
            # æµ‹è¯•æ•°æ®åº“è¿æ¥
            test_study = optuna.create_study(
                direction="minimize",
                study_name=f"test_{timestamp}",
                storage=storage_url
            )
            print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
            storage_name = storage_url
            
        except Exception as e:
            print(f"âš ï¸ æ•°æ®åº“è®¾ç½®å¤±è´¥: {e}")
            print("ğŸ”„ ä½¿ç”¨å†…å­˜å­˜å‚¨æ¨¡å¼")
            storage_name = None
        
        # ğŸ”§ ç¬¬äºŒæ­¥ï¼šåˆ›å»ºStudy
        try:
            study = optuna.create_study(
                direction="minimize",
                study_name=config.project_name,
                storage=storage_name,
                sampler=optuna.samplers.TPESampler(
                    seed=config.seed,
                    n_startup_trials=max(2, config.sweep_count // 5)
                ),
                pruner=optuna.pruners.MedianPruner(
                    n_startup_trials=2,
                    n_warmup_steps=3,  # å‰3ä¸ªepochä¸å‰ªæ
                    interval_steps=1
                ),
                load_if_exists=True
            )
            print("âœ… Optuna studyåˆ›å»ºæˆåŠŸ")
        except Exception as e:
            print(f"âŒ Studyåˆ›å»ºå¤±è´¥: {e}")
            # æœ€ç®€å•çš„fallback
            study = optuna.create_study(direction="minimize")
            print("ğŸ”„ ä½¿ç”¨åŸºç¡€é…ç½®")
        
        # ğŸ”§ ç¬¬ä¸‰æ­¥ï¼šå®šä¹‰ç›®æ ‡å‡½æ•°
        def hyperparameter_objective(trial):
            """
            è¶…å‚æ•°ä¼˜åŒ–ç›®æ ‡å‡½æ•°
            """
            trial_start_time = time.time()
            
            try:
                # æ¸…ç†èµ„æº
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                gc.collect()
                
                # æ·±æ‹·è´é…ç½®
                trial_config = copy.deepcopy(config)
                
                # ğŸ¯ è¶…å‚æ•°æœç´¢ç©ºé—´
                trial_config.lr = trial.suggest_float("lr", 0.0005, 0.003, log=True)
                trial_config.dropout_rate = trial.suggest_float("dropout_rate", 0.05, 0.25)
                
                # ä¼˜åŒ–å™¨å‚æ•°
                weight_decay = trial.suggest_float("weight_decay", 1e-6, 1e-3, log=True)
                trial_config.optimizer_args = trial_config.optimizer_args.copy()
                trial_config.optimizer_args['weight_decay'] = weight_decay
                
                # ç½‘ç»œç»“æ„
                trial_config.firstUpdateLayers = trial.suggest_categorical("firstUpdateLayers", [3, 4, 5])
                trial_config.secondUpdateLayers = trial.suggest_categorical("secondUpdateLayers", [3, 4, 5])
                trial_config.hidden_features = trial.suggest_categorical("hidden_features", [96, 128, 160, 192])
                
                # æ ¹æ®GPUé€‰æ‹©batch size
                if "4090" in config.project_name.lower():
                    trial_config.batch_size = trial.suggest_categorical("batch_size", [32, 48, 64, 96])
                else:
                    trial_config.batch_size = trial.suggest_categorical("batch_size", [16, 24, 32, 48])
                
                # ğŸš€ æ˜¾ç¤ºè¯•éªŒä¿¡æ¯
                print(f"\n{'='*60}")
                print(f"ğŸš€ Trial #{trial.number} å¼€å§‹")
                print(f"â±ï¸  é¢„è®¡ç”¨æ—¶: {config.epochs * 2:.1f}åˆ†é’Ÿ")
                print("ğŸ“‹ å‚æ•°:")
                for key, value in trial.params.items():
                    print(f"    {key}: {value}")
                print(f"{'='*60}")
                
                # ğŸ”§ é…ç½®è°ƒæ•´
                trial_config.log_enable = False  # å…³é—­wandb
                
                # åˆ›å»ºè¯•éªŒç›®å½•
                trial_name = f"trial_{trial.number:03d}"
                trial_config.output_dir = os.path.join(config.output_dir, trial_name)
                os.makedirs(trial_config.output_dir, exist_ok=True)
                
                # è®¾ç½®ç‹¬ç‰¹çš„éšæœºç§å­
                trial_config.seed = config.seed + trial.number * 42
                set_seed(trial_config.seed)
                
                # ğŸƒâ€â™‚ï¸ æ‰§è¡Œè®­ç»ƒ
                best_val_mae = train(trial_config, printnet=False, trial=trial)
                
                # ğŸ“Š æ˜¾ç¤ºç»“æœ
                trial_time = time.time() - trial_start_time
                print(f"\nğŸ Trial #{trial.number} å®Œæˆ!")
                print(f"â±ï¸  è€—æ—¶: {trial_time/60:.1f}åˆ†é’Ÿ")
                print(f"ğŸ“ˆ éªŒè¯MAE: {best_val_mae:.6f}")
                
                # æ˜¾ç¤ºæ’å
                try:
                    completed_trials = [t for t in trial.study.trials 
                                    if t.state == optuna.trial.TrialState.COMPLETE]
                    if len(completed_trials) > 1:
                        current_rank = sorted([t.value for t in completed_trials]).index(best_val_mae) + 1
                        print(f"ğŸ† å½“å‰æ’å: {current_rank}/{len(completed_trials)}")
                        print(f"ğŸ¥‡ æœ€ä½³æˆç»©: {trial.study.best_value:.6f}")
                except:
                    pass
                
                print(f"{'='*60}")
                return best_val_mae
                
            except optuna.exceptions.TrialPruned:
                trial_time = time.time() - trial_start_time
                print(f"\nâœ‚ï¸ Trial #{trial.number} è¢«å‰ªæ")
                print(f"â±ï¸  èŠ‚çœæ—¶é—´: {trial_time/60:.1f}åˆ†é’Ÿ")
                print(f"{'='*60}")
                raise
                
            except torch.cuda.OutOfMemoryError:
                print(f"\nğŸ’¥ Trial #{trial.number} GPUå†…å­˜ä¸è¶³")
                print(f"ğŸ”§ å»ºè®®: å‡å°‘batch_sizeæˆ–hidden_features")
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                print(f"{'='*60}")
                return float('inf')
                
            except Exception as e:
                trial_time = time.time() - trial_start_time
                print(f"\nâŒ Trial #{trial.number} å¤±è´¥")
                print(f"âš ï¸  é”™è¯¯: {str(e)[:100]}...")
                print(f"â±ï¸  è€—æ—¶: {trial_time/60:.1f}åˆ†é’Ÿ")
                
                # æ¸…ç†èµ„æº
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                gc.collect()
                
                print(f"{'='*60}")
                return float('inf')
            
            finally:
                # æœ€ç»ˆæ¸…ç†
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                gc.collect()
        
        # ğŸ”§ ç¬¬å››æ­¥ï¼šæ‰§è¡Œä¼˜åŒ–
        print(f"\nğŸ¯ å¼€å§‹è¶…å‚æ•°ä¼˜åŒ–")
        print(f"ğŸ“Š è®¡åˆ’è¯•éªŒæ•°: {config.sweep_count}")
        print(f"ğŸ’¾ å­˜å‚¨æ¨¡å¼: {'æ•°æ®åº“' if storage_name else 'å†…å­˜'}")
        if storage_name:
            print(f"ğŸ“ æ•°æ®åº“æ–‡ä»¶: {db_path}")
        print(f"{'='*60}")
        
        optimization_start = time.time()
        
        try:
            study.optimize(
                hyperparameter_objective,
                n_trials=config.sweep_count,
                timeout=None,
                catch=(Exception,),  # æ•è·å¼‚å¸¸ä½†ç»§ç»­
                show_progress_bar=True
            )
        except KeyboardInterrupt:
            print(f"\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­ä¼˜åŒ–")
        except Exception as e:
            print(f"\nğŸ’¥ ä¼˜åŒ–è¿‡ç¨‹å‡ºé”™: {e}")
        
        # ğŸ”§ ç¬¬äº”æ­¥ï¼šç»“æœåˆ†æ
        optimization_time = time.time() - optimization_start
        
        print(f"\n{'='*60}")
        print(f"ğŸ‰ ä¼˜åŒ–å®Œæˆ!")
        print(f"â±ï¸  æ€»è€—æ—¶: {optimization_time/3600:.1f}å°æ—¶")
        
        # ç»Ÿè®¡ä¿¡æ¯
        all_trials = study.trials
        completed = [t for t in all_trials if t.state == optuna.trial.TrialState.COMPLETE]
        pruned = [t for t in all_trials if t.state == optuna.trial.TrialState.PRUNED]
        failed = [t for t in all_trials if t.state == optuna.trial.TrialState.FAIL]
        
        print(f"\nğŸ“Š è¯•éªŒç»Ÿè®¡:")
        print(f"   æ€»è¯•éªŒ: {len(all_trials)}")
        print(f"   æˆåŠŸ: {len(completed)}")
        print(f"   å‰ªæ: {len(pruned)} (èŠ‚çœ {len(pruned)/(len(all_trials) or 1)*100:.1f}%)")
        print(f"   å¤±è´¥: {len(failed)}")
        
        # æœ€ä½³ç»“æœ
        if completed:
            best_trial = study.best_trial
            print(f"\nğŸ† æœ€ä½³ç»“æœ:")
            print(f"   Trial: #{best_trial.number}")
            print(f"   éªŒè¯MAE: {study.best_value:.6f}")
            print(f"   å‚æ•°:")
            for key, value in study.best_params.items():
                print(f"     {key}: {value}")
            
            # ä¿å­˜ç»“æœ
            results_file = os.path.join(config.output_dir, "best_hyperparameters.txt")
            with open(results_file, 'w', encoding='utf-8') as f:
                f.write(f"æœ€ä½³Trial: #{best_trial.number}\n")
                f.write(f"æœ€ä½³éªŒè¯MAE: {study.best_value:.6f}\n")
                f.write(f"ä¼˜åŒ–è€—æ—¶: {optimization_time/3600:.2f}å°æ—¶\n\n")
                f.write("æœ€ä½³è¶…å‚æ•°:\n")
                for key, value in study.best_params.items():
                    f.write(f"{key}: {value}\n")
            
            print(f"\nğŸ’¾ ç»“æœä¿å­˜è‡³: {results_file}")
            
            # ç”Ÿæˆé…ç½®æ–‡ä»¶
            best_config_file = os.path.join(config.output_dir, "best_config.yml")
            try:
                import yaml
                best_config_dict = {
                    'project_name': f"{config.project_name}_best",
                    'hyperParameters': {
                        'lr': study.best_params['lr'],
                        'optimizer_args': {'weight_decay': study.best_params['weight_decay']},
                        'epochs': 100,  # ç”¨äºæœ€ç»ˆè®­ç»ƒ
                    },
                    'netAttributes': {
                        'firstUpdateLayers': study.best_params['firstUpdateLayers'],
                        'secondUpdateLayers': study.best_params['secondUpdateLayers'],
                        'hidden_features': study.best_params['hidden_features'],
                        'batch_size': study.best_params.get('batch_size', config.batch_size),
                        'dropout_rate': study.best_params['dropout_rate'],
                    }
                }
                
                with open(best_config_file, 'w', encoding='utf-8') as f:
                    yaml.dump(best_config_dict, f, default_flow_style=False, allow_unicode=True)
                print(f"ğŸ”§ æœ€ä½³é…ç½®ä¿å­˜è‡³: {best_config_file}")
            except:
                print("âš ï¸ æ— æ³•ç”ŸæˆYAMLé…ç½®æ–‡ä»¶")
        else:
            print(f"\nâŒ æ²¡æœ‰æˆåŠŸå®Œæˆçš„è¯•éªŒ")
            print(f"ğŸ”§ å»ºè®®æ£€æŸ¥:")
            print(f"   - æ•°æ®è·¯å¾„: {config.dataset_path}")
            print(f"   - GPUå†…å­˜æ˜¯å¦å……è¶³")
            print(f"   - epochsæ˜¯å¦å¤ªå°‘: {config.epochs}")
        
        if storage_name and os.path.exists(db_path):
            print(f"ğŸ’¾ æ•°æ®åº“ä¿å­˜è‡³: {db_path}")
        
        print(f"{'='*60}")