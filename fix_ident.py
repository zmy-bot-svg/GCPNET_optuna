#!/usr/bin/env python3
"""
ä¸“é—¨ä¿®å¤train_utils.pyç¼©è¿›é—®é¢˜çš„è„šæœ¬
"""

def check_and_fix_indentation():
    """æ£€æŸ¥å¹¶ä¿®å¤train_utils.pyçš„ç¼©è¿›é—®é¢˜"""
    
    print("ğŸ” åˆ†æ utils/train_utils.py çš„ç¼©è¿›é—®é¢˜...")
    
    with open('utils/train_utils.py', 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    # æ£€æŸ¥KerasModelç±»çš„æ–¹æ³•
    print("\nğŸ“Š KerasModelç±»æ–¹æ³•æ£€æŸ¥:")
    in_keras_model = False
    keras_model_methods = []
    
    for i, line in enumerate(lines, 1):
        if 'class KerasModel' in line:
            in_keras_model = True
            print(f"è¡Œ {i}: æ‰¾åˆ°KerasModelç±»å®šä¹‰")
            continue
        
        if in_keras_model:
            # å¦‚æœé‡åˆ°ä¸‹ä¸€ä¸ªç±»å®šä¹‰ï¼Œåœæ­¢
            if line.strip().startswith('class ') and 'KerasModel' not in line:
                print(f"è¡Œ {i}: é‡åˆ°ä¸‹ä¸€ä¸ªç±» {line.strip()}")
                break
            
            # æ£€æŸ¥æ–¹æ³•å®šä¹‰
            if 'def ' in line and not line.strip().startswith('#'):
                indent_count = len(line) - len(line.lstrip())
                method_name = line.strip().split('def ')[1].split('(')[0]
                keras_model_methods.append((i, method_name, indent_count))
                print(f"è¡Œ {i}: æ–¹æ³• {method_name} - ç¼©è¿›: {indent_count}ä¸ªç©ºæ ¼")
    
    print(f"\nğŸ“‹ KerasModelç±»ä¸­æ‰¾åˆ° {len(keras_model_methods)} ä¸ªæ–¹æ³•:")
    for line_num, method_name, indent in keras_model_methods:
        status = "âœ…" if indent == 4 else "âŒ"
        print(f"  {status} {method_name}: {indent}ä¸ªç©ºæ ¼ç¼©è¿›")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç¼©è¿›é”™è¯¯
    wrong_indent_methods = [m for m in keras_model_methods if m[2] != 4]
    
    if wrong_indent_methods:
        print(f"\nğŸš¨ å‘ç° {len(wrong_indent_methods)} ä¸ªç¼©è¿›é”™è¯¯çš„æ–¹æ³•")
        
        # ä¿®å¤ç¼©è¿›
        print("ğŸ”§ å¼€å§‹ä¿®å¤ç¼©è¿›...")
        
        new_lines = []
        for i, line in enumerate(lines):
            line_num = i + 1
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯éœ€è¦ä¿®å¤çš„æ–¹æ³•è¡Œ
            needs_fix = False
            for wrong_line, method_name, wrong_indent in wrong_indent_methods:
                if line_num == wrong_line:
                    needs_fix = True
                    break
            
            if needs_fix:
                # ä¿®å¤æ–¹æ³•å®šä¹‰è¡Œçš„ç¼©è¿›
                if 'def ' in line or '@torch.no_grad()' in line:
                    new_line = '    ' + line.lstrip()
                    new_lines.append(new_line)
                    print(f"  ä¿®å¤è¡Œ {line_num}: {line.strip()} -> 4ä¸ªç©ºæ ¼ç¼©è¿›")
                else:
                    new_lines.append(line)
            else:
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ–¹æ³•å†…éƒ¨çš„ä»£ç ï¼ˆéœ€è¦ç›¸åº”è°ƒæ•´ç¼©è¿›ï¼‰
                if line.strip() and not line.strip().startswith('#'):
                    # å¦‚æœå½“å‰è¡Œç¼©è¿›è¿‡æ·±ï¼Œä¸”åœ¨é”™è¯¯æ–¹æ³•çš„èŒƒå›´å†…
                    current_indent = len(line) - len(line.lstrip())
                    if current_indent > 4 and any(line_num > wrong_line for wrong_line, _, _ in wrong_indent_methods):
                        # æ£€æŸ¥æ˜¯å¦åœ¨æ–¹æ³•å†…éƒ¨
                        in_wrong_method = False
                        for wrong_line, _, _ in wrong_indent_methods:
                            if line_num > wrong_line:
                                # æ£€æŸ¥æ˜¯å¦è¿˜åœ¨è¿™ä¸ªæ–¹æ³•å†…éƒ¨
                                for j in range(i+1, min(len(lines), i+20)):
                                    if lines[j].strip().startswith('def ') or lines[j].strip().startswith('class '):
                                        if j < i + 10:  # å¦‚æœå¾ˆå¿«é‡åˆ°ä¸‹ä¸€ä¸ªæ–¹æ³•ï¼Œè¯´æ˜å½“å‰è¡Œåœ¨æ–¹æ³•å†…éƒ¨
                                            in_wrong_method = True
                                        break
                        
                        if in_wrong_method and current_indent == 8:
                            # å°†8ä¸ªç©ºæ ¼æ”¹ä¸º8ä¸ªç©ºæ ¼ï¼ˆæ–¹æ³•å†…éƒ¨ä»£ç ï¼‰
                            new_line = '        ' + line.lstrip()
                            new_lines.append(new_line)
                        else:
                            new_lines.append(line)
                    else:
                        new_lines.append(line)
                else:
                    new_lines.append(line)
        
        # å†™å…¥ä¿®å¤åçš„æ–‡ä»¶
        with open('utils/train_utils.py', 'w', encoding='utf-8') as f:
            f.writelines(new_lines)
        
        print("âœ… ç¼©è¿›ä¿®å¤å®Œæˆ")
        
        # éªŒè¯ä¿®å¤ç»“æœ
        print("\nğŸ” éªŒè¯ä¿®å¤ç»“æœ...")
        try:
            from utils.train_utils import KerasModel
            methods = ['evaluate', 'predict', 'cubic', 'analysis', 'total_params']
            missing = []
            for method in methods:
                if hasattr(KerasModel, method):
                    print(f"  âœ… {method} æ–¹æ³•å­˜åœ¨")
                else:
                    print(f"  âŒ {method} æ–¹æ³•ä¸å­˜åœ¨")
                    missing.append(method)
            
            if missing:
                print(f"\nâŒ ä»æœ‰é—®é¢˜ï¼Œç¼ºå°‘æ–¹æ³•: {missing}")
                return False
            else:
                print("\nğŸ‰ æ‰€æœ‰æ–¹æ³•éƒ½æ­£ç¡®å­˜åœ¨ï¼")
                return True
                
        except Exception as e:
            print(f"\nâŒ å¯¼å…¥æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    else:
        print("\nâœ… æ‰€æœ‰æ–¹æ³•ç¼©è¿›éƒ½æ­£ç¡®")
        return True

def manual_fix_if_needed():
    """å¦‚æœè‡ªåŠ¨ä¿®å¤å¤±è´¥ï¼Œæä¾›æ‰‹åŠ¨ä¿®å¤æ–¹æ¡ˆ"""
    print("\nğŸ”§ å°è¯•æ‰‹åŠ¨ä¿®å¤æ–¹æ¡ˆ...")
    
    with open('utils/train_utils.py', 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æ‰¾åˆ°fitæ–¹æ³•çš„ç»“æŸä½ç½®
    fit_end_marker = 'return dfhistory'
    lrscheduler_start_marker = 'class LRScheduler:'
    
    if fit_end_marker in content and lrscheduler_start_marker in content:
        parts = content.split(fit_end_marker)
        if len(parts) >= 2:
            before_fit_end = parts[0] + fit_end_marker
            
            # æ‰¾åˆ°LRSchedulerç±»çš„å¼€å§‹
            remaining = fit_end_marker.join(parts[1:])
            lr_parts = remaining.split(lrscheduler_start_marker)
            
            if len(lr_parts) >= 2:
                methods_part = lr_parts[0]
                after_lr = lrscheduler_start_marker + lrscheduler_start_marker.join(lr_parts[1:])
                
                # é‡å†™methodséƒ¨åˆ†ï¼Œç¡®ä¿æ­£ç¡®çš„ç¼©è¿›
                fixed_methods = '''

    # æ¨¡å‹è¯„ä¼°æ–¹æ³•ï¼Œç”¨äºåœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½
    @torch.no_grad()
    def evaluate(self, val_data):
        accelerator = Accelerator()
        self.net, self.loss_fn, self.metrics_dict = accelerator.prepare(
            self.net, self.loss_fn, self.metrics_dict)
        val_data = accelerator.prepare(val_data)
        
        val_step_runner = self.StepRunner(
            net=self.net, stage="val",
            loss_fn=self.loss_fn, 
            metrics_dict=deepcopy(self.metrics_dict),
            accelerator=accelerator
        )
        
        val_epoch_runner = self.EpochRunner(val_step_runner)
        val_metrics = val_epoch_runner(val_data)
        return val_metrics
        
    @torch.no_grad()
    def predict(self, test_data, ckpt_path, test_out_path='test_out.csv'):
        self.ckpt_path = ckpt_path
        self.load_ckpt(self.ckpt_path)
        self.net.eval()
        
        targets = []
        outputs = []
        id = []
        
        for data in test_data:
            data = data.to(torch.device('cuda'))
            targets.append(data.y.cpu().numpy().tolist())
            output = self.net(data)
            outputs.append(output.cpu().numpy().tolist())
            id += data.structure_id
        
        targets = sum(targets, [])
        outputs = sum(outputs, [])
        id = sum(sum(id, []), [])
        
        import csv
        rows = zip(id, targets, outputs)
        with open(test_out_path, "w") as csv_file:
            writer = csv.writer(csv_file, delimiter=",")
            for row in rows:
                writer.writerow(row)

    @torch.no_grad()
    def cubic(self, test_data, ckpt_path, test_out_path='cubic_out.csv'):
        self.ckpt_path = ckpt_path
        self.load_ckpt(self.ckpt_path)
        self.net.eval()
        
        targets = []
        outputs = []
        id = []
        
        for data in test_data:
            data = data.to(torch.device('cuda'))
            targets.append(data.y.cpu().numpy().tolist())
            output = self.net(data)
            outputs.append(output.cpu().numpy().tolist())
            id += data.structure_id
        
        targets = sum(targets, [])
        outputs = sum(outputs, [])
        id = sum(sum(id, []), [])
        
        import csv
        rows = zip(id, targets, outputs)
        with open(test_out_path, "w") as csv_file:
            writer = csv.writer(csv_file, delimiter=",")
            for row in rows:
                writer.writerow(row)

    @torch.no_grad()
    def analysis(self, net_name, test_data, ckpt_path, tsne_args, tsne_file_path="tsne_output.png"):
        from sklearn.decomposition import PCA
        from sklearn.manifold import TSNE
        import matplotlib.pyplot as plt
        
        inputs = []
        def hook(module, input, output):
            inputs.append(input)

        self.ckpt_path = ckpt_path
        self.load_ckpt(self.ckpt_path)
        self.net.eval()
        
        if net_name in ["ALIGNN", "CLIGNN", "GCPNet"]:
            self.net.fc.register_forward_hook(hook)
        else:
            self.net.post_lin_list[0].register_forward_hook(hook)

        targets = []
        for data in test_data:
            data = data.to(torch.device('cuda'))
            targets.append(data.y.cpu().numpy().tolist())
            _ = self.net(data)

        targets = sum(targets, [])
        inputs = [i for sub in inputs for i in sub]
        inputs = torch.cat(inputs)
        inputs = inputs.cpu().numpy()
        
        print("Number of samples: ", inputs.shape[0])
        print("Number of features: ", inputs.shape[1])

        tsne = TSNE(**tsne_args)
        tsne_out = tsne.fit_transform(inputs)

        fig, ax = plt.subplots()
        main = plt.scatter(tsne_out[:, 1], tsne_out[:, 0], c=targets, s=3, cmap='coolwarm')
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_xticks([])
        ax.set_yticks([])
        cbar = plt.colorbar(main, ax=ax)
        stdev = np.std(targets)
        cbar.mappable.set_clim(
            np.mean(targets) - 2 * np.std(targets), 
            np.mean(targets) + 2 * np.std(targets)
        )
        plt.savefig(tsne_file_path, format="png", dpi=600)
        plt.show()

    def total_params(self):
        return self.net.total_params()

'''
                
                # é‡æ–°ç»„åˆæ–‡ä»¶
                new_content = before_fit_end + fixed_methods + '\n' + after_lr
                
                with open('utils/train_utils.py', 'w', encoding='utf-8') as f:
                    f.write(new_content)
                
                print("âœ… æ‰‹åŠ¨ä¿®å¤å®Œæˆ")
                return True
    
    print("âŒ æ‰‹åŠ¨ä¿®å¤å¤±è´¥")
    return False

def main():
    print("ğŸš€ train_utils.py ç¼©è¿›ä¿®å¤å·¥å…·")
    print("=" * 50)
    
    # å¤‡ä»½æ–‡ä»¶
    import shutil
    from datetime import datetime
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_path = f"utils/train_utils.py.backup_indent_{timestamp}"
    shutil.copy2("utils/train_utils.py", backup_path)
    print(f"ğŸ“ å·²å¤‡ä»½åˆ°: {backup_path}")
    
    # å°è¯•è‡ªåŠ¨ä¿®å¤
    success = check_and_fix_indentation()
    
    if not success:
        print("\nğŸ”§ è‡ªåŠ¨ä¿®å¤å¤±è´¥ï¼Œå°è¯•æ‰‹åŠ¨ä¿®å¤...")
        success = manual_fix_if_needed()
    
    if success:
        print("\nğŸ‰ ä¿®å¤æˆåŠŸï¼")
        print("ğŸš€ ç°åœ¨å¯ä»¥è¿è¡Œ:")
        print("   python main.py --config config_tiny.yml --task_type train")
    else:
        print("\nâŒ ä¿®å¤å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥ç¼©è¿›é—®é¢˜")
        print("ğŸ’¡ å¯èƒ½éœ€è¦æ‰‹åŠ¨ç¼–è¾‘ utils/train_utils.py")
        print("   ç¡®ä¿ evaluate, predict, cubic, analysis, total_params æ–¹æ³•")
        print("   éƒ½æœ‰æ­£ç¡®çš„4ä¸ªç©ºæ ¼ç¼©è¿›")

if __name__ == "__main__":
    main()