#!/usr/bin/env python3
"""
Optunaè¶…å‚æ•°ä¼˜åŒ–å™¨æ¨¡å—
å°†è¶…å‚æ•°æœç´¢é€»è¾‘æ¨¡å—åŒ–ï¼Œå¢å¼ºå¯è§†åŒ–åŠŸèƒ½
"""

import os
import sys
import time
import copy
import datetime
import gc
import signal
import psutil
import torch
import optuna
import optuna.visualization as vis
from optuna.exceptions import TrialPruned


class OptunaHyperparameterOptimizer:
    """Optunaè¶…å‚æ•°ä¼˜åŒ–å™¨"""
    
    def __init__(self, config, train_function):
        """
        åˆå§‹åŒ–ä¼˜åŒ–å™¨
        
        Args:
            config: é…ç½®å¯¹è±¡
            train_function: è®­ç»ƒå‡½æ•°
        """
        self.config = config
        self.train_function = train_function
        self.study = None
        self.storage_name = None
        self.db_path = None
        
    def setup_storage(self):
        """è®¾ç½®æ•°æ®åº“å­˜å‚¨"""
        try:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(self.config.output_dir, exist_ok=True)
            
            # æ£€æŸ¥å†™å…¥æƒé™
            if not os.access(self.config.output_dir, os.W_OK):
                raise PermissionError(f"è¾“å‡ºç›®å½•æ— å†™å…¥æƒé™: {self.config.output_dir}")
            
            # åˆ›å»ºæ•°æ®åº“æ–‡ä»¶å
            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
            db_name = f"{self.config.project_name}_{timestamp}.db"
            self.db_path = os.path.abspath(os.path.join(self.config.output_dir, db_name))
            
            # å…¼å®¹ä¸åŒæ“ä½œç³»ç»Ÿçš„å­˜å‚¨URL
            self.storage_name = f"sqlite:///{self.db_path}"
            
            print(f"ğŸ“ æ•°æ®åº“è·¯å¾„: {self.db_path}")
            
            # æµ‹è¯•æ•°æ®åº“è¿æ¥
            test_study = optuna.create_study(
                direction="minimize",
                study_name=f"test_{timestamp}",
                storage=self.storage_name
            )
            print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
            
            # æ¸…ç†æµ‹è¯•study
            try:
                optuna.delete_study(study_name=f"test_{timestamp}", storage=self.storage_name)
            except:
                pass
                
        except Exception as e:
            print(f"âš ï¸ æ•°æ®åº“è®¾ç½®å¤±è´¥: {e}")
            print("ğŸ”„ ä½¿ç”¨å†…å­˜å­˜å‚¨æ¨¡å¼")
            self.storage_name = None
            self.db_path = None
    
    def create_study(self):
        """åˆ›å»ºOptuna study"""
        try:
            self.study = optuna.create_study(
                direction="minimize",
                study_name=self.config.project_name,
                storage=self.storage_name,
                sampler=optuna.samplers.TPESampler(
                    seed=self.config.seed,
                    n_startup_trials=max(2, self.config.sweep_count // 5)
                ),
                pruner=optuna.pruners.MedianPruner(
                    n_startup_trials=2,
                    n_warmup_steps=3,
                    interval_steps=1
                ),
                load_if_exists=True  # æ”¯æŒæ–­ç‚¹ç»­ä¼ 
            )
            print("âœ… Optuna studyåˆ›å»ºæˆåŠŸ")
            
            # å¦‚æœæ˜¯ç»­ä¼ ï¼Œæ˜¾ç¤ºå·²æœ‰è¯•éªŒä¿¡æ¯
            existing_trials = len(self.study.trials)
            if existing_trials > 0:
                print(f"ğŸ”„ æ£€æµ‹åˆ°å·²æœ‰è¯•éªŒ: {existing_trials}ä¸ª")
                print(f"ğŸ“Š å°†ä»ç¬¬{existing_trials + 1}ä¸ªè¯•éªŒç»§ç»­...")
                
        except Exception as e:
            print(f"âŒ Studyåˆ›å»ºå¤±è´¥: {e}")
            self.study = optuna.create_study(direction="minimize")
            print("ğŸ”„ ä½¿ç”¨åŸºç¡€é…ç½®")
    
    def get_search_space_params(self, trial):
        """å®šä¹‰æœç´¢ç©ºé—´å‚æ•°"""
        params = {}
        
        # åŸºç¡€è¶…å‚æ•°
        params['lr'] = trial.suggest_float("lr", 0.0005, 0.003, log=True)
        params['dropout_rate'] = trial.suggest_float("dropout_rate", 0.05, 0.25)
        params['weight_decay'] = trial.suggest_float("weight_decay", 1e-6, 1e-3, log=True)
        
        # ç½‘ç»œç»“æ„
        params['firstUpdateLayers'] = trial.suggest_categorical("firstUpdateLayers", [3, 4, 5])
        params['secondUpdateLayers'] = trial.suggest_categorical("secondUpdateLayers", [3, 4, 5])
        params['hidden_features'] = trial.suggest_categorical("hidden_features", [96, 128, 160, 192])
        
        # åŠ¨æ€batch sizeè°ƒæ•´
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
            if gpu_memory > 40:  # A100ç­‰
                batch_options = [64, 96, 128, 160, 192]
            elif gpu_memory > 20:  # V100, A6000ç­‰
                batch_options = [48, 64, 96, 128]
            elif gpu_memory > 10:  # 4090, 3090ç­‰
                batch_options = [32, 48, 64, 96]
            else:  # å°æ˜¾å­˜å¡
                batch_options = [16, 24, 32, 48]
            params['batch_size'] = trial.suggest_categorical("batch_size", batch_options)
        else:
            params['batch_size'] = trial.suggest_categorical("batch_size", [16, 24, 32])
        
        return params
    
    def apply_params_to_config(self, trial_config, params):
        """å°†å‚æ•°åº”ç”¨åˆ°é…ç½®å¯¹è±¡"""
        # åŸºç¡€å‚æ•°
        trial_config.lr = params['lr']
        trial_config.dropout_rate = params['dropout_rate']
        
        # ä¼˜åŒ–å™¨å‚æ•°
        trial_config.optimizer_args = trial_config.optimizer_args.copy()
        trial_config.optimizer_args['weight_decay'] = params['weight_decay']
        
        # ç½‘ç»œç»“æ„
        trial_config.firstUpdateLayers = params['firstUpdateLayers']
        trial_config.secondUpdateLayers = params['secondUpdateLayers']
        trial_config.hidden_features = params['hidden_features']
        trial_config.batch_size = params['batch_size']
        
        # CPU workersä¼˜åŒ–
        if hasattr(psutil, 'cpu_count'):
            cpu_cores = psutil.cpu_count(logical=False)
            max_workers = min(cpu_cores // 2, 8)
            trial_config.num_workers = min(trial_config.num_workers, max_workers)
        
        return trial_config
    
    def objective_function(self, trial):
        """ä¼˜åŒ–ç›®æ ‡å‡½æ•°"""
        trial_start_time = time.time()
        
        # è®¾ç½®ä¿¡å·å¤„ç†
        def cleanup_handler(signum, frame):
            print(f"\nğŸ›‘ Trial #{trial.number} æ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨æ¸…ç†...")
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            sys.exit(1)
        
        original_sigint = signal.signal(signal.SIGINT, cleanup_handler)
        original_sigterm = signal.signal(signal.SIGTERM, cleanup_handler)
        
        try:
            # ç³»ç»Ÿèµ„æºæ£€æŸ¥
            if hasattr(psutil, 'virtual_memory'):
                memory = psutil.virtual_memory()
                if memory.percent > 90:
                    print(f"âš ï¸ ç³»ç»Ÿå†…å­˜ä½¿ç”¨è¿‡é«˜: {memory.percent:.1f}%")
                    return float('inf')
            
            # æ¸…ç†èµ„æº
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            # æ·±æ‹·è´é…ç½®
            trial_config = copy.deepcopy(self.config)
            
            # è·å–æœç´¢å‚æ•°
            params = self.get_search_space_params(trial)
            
            # åº”ç”¨å‚æ•°åˆ°é…ç½®
            trial_config = self.apply_params_to_config(trial_config, params)
            
            # æ˜¾ç¤ºè¯•éªŒä¿¡æ¯
            self.print_trial_info(trial, params, trial_config)
            
            # é…ç½®è°ƒæ•´
            trial_config.log_enable = False
            
            # åˆ›å»ºè¯•éªŒç›®å½•
            trial_name = f"trial_{trial.number:03d}"
            trial_config.output_dir = os.path.join(self.config.output_dir, trial_name)
            os.makedirs(trial_config.output_dir, exist_ok=True)
            
            # æƒé™æ£€æŸ¥
            if not os.access(trial_config.output_dir, os.W_OK):
                raise PermissionError(f"è¯•éªŒç›®å½•æ— å†™å…¥æƒé™: {trial_config.output_dir}")
            
            # è®¾ç½®éšæœºç§å­
            trial_config.seed = self.config.seed + trial.number * 42
            self.set_seed(trial_config.seed)
            
            # æ‰§è¡Œè®­ç»ƒ
            best_val_mae = self.train_function(trial_config, printnet=False, trial=trial)
            
            # æ˜¾ç¤ºç»“æœ
            self.print_trial_results(trial, best_val_mae, trial_start_time)
            
            return best_val_mae
            
        except TrialPruned:
            trial_time = time.time() - trial_start_time
            print(f"\nâœ‚ï¸ Trial #{trial.number} è¢«å‰ªæ")
            print(f"â±ï¸  èŠ‚çœæ—¶é—´: {trial_time/60:.1f}åˆ†é’Ÿ")
            raise
            
        except torch.cuda.OutOfMemoryError:
            print(f"\nğŸ’¥ Trial #{trial.number} GPUå†…å­˜ä¸è¶³")
            suggested_batch = max(16, params.get('batch_size', 32) // 2)
            print(f"ğŸ”§ å»ºè®®batch_size: {suggested_batch}")
            return float('inf')
            
        except Exception as e:
            trial_time = time.time() - trial_start_time
            print(f"\nâŒ Trial #{trial.number} å¤±è´¥")
            print(f"âš ï¸  é”™è¯¯: {str(e)[:100]}...")
            print(f"â±ï¸  è€—æ—¶: {trial_time/60:.1f}åˆ†é’Ÿ")
            return float('inf')
        
        finally:
            # æ¢å¤ä¿¡å·å¤„ç†å™¨
            signal.signal(signal.SIGINT, original_sigint)
            signal.signal(signal.SIGTERM, original_sigterm)
            
            # æœ€ç»ˆæ¸…ç†
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
    
    def print_trial_info(self, trial, params, trial_config):
        """æ‰“å°è¯•éªŒä¿¡æ¯"""
        print(f"\n{'='*60}")
        print(f"ğŸš€ Trial #{trial.number} å¼€å§‹")
        
        if hasattr(psutil, 'virtual_memory'):
            memory = psutil.virtual_memory()
            print(f"ğŸ–¥ï¸  èµ„æºçŠ¶æ€:")
            print(f"    å†…å­˜ä½¿ç”¨: {memory.percent:.1f}%")
            
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
            print(f"    GPUæ˜¾å­˜: {gpu_memory:.1f}GB")
            
        print(f"â±ï¸  é¢„è®¡ç”¨æ—¶: {self.config.epochs * 2:.1f}åˆ†é’Ÿ")
        print("ğŸ“‹ è¶…å‚æ•°:")
        for key, value in params.items():
            print(f"    {key}: {value}")
        print(f"{'='*60}")
    
    def print_trial_results(self, trial, best_val_mae, trial_start_time):
        """æ‰“å°è¯•éªŒç»“æœ"""
        trial_time = time.time() - trial_start_time
        
        print(f"\nğŸ Trial #{trial.number} å®Œæˆ!")
        print(f"â±ï¸  è€—æ—¶: {trial_time/60:.1f}åˆ†é’Ÿ")
        print(f"ğŸ“ˆ éªŒè¯MAE: {best_val_mae:.6f}")
        
        if hasattr(psutil, 'virtual_memory'):
            memory = psutil.virtual_memory()
            print(f"ğŸ’¾ å†…å­˜ä½¿ç”¨: {memory.percent:.1f}%")
        
        # æ˜¾ç¤ºæ’å
        try:
            completed_trials = [t for t in trial.study.trials 
                              if t.state == optuna.trial.TrialState.COMPLETE]
            if len(completed_trials) > 1:
                sorted_values = sorted([t.value for t in completed_trials])
                current_rank = sorted_values.index(best_val_mae) + 1
                print(f"ğŸ† å½“å‰æ’å: {current_rank}/{len(completed_trials)}")
                print(f"ğŸ¥‡ æœ€ä½³æˆç»©: {trial.study.best_value:.6f}")
        except:
            pass
        
        print(f"{'='*60}")
    
    def set_seed(self, seed):
        """è®¾ç½®éšæœºç§å­"""
        import random
        import numpy as np
        random.seed(seed)
        np.random.seed(seed)
        torch.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
    
    def generate_visualizations(self):
        """ç”Ÿæˆå¯è§†åŒ–æ–‡ä»¶"""
        if self.study is None or len(self.study.trials) == 0:
            print("âš ï¸ æ²¡æœ‰å¯ç”¨çš„è¯•éªŒæ•°æ®ï¼Œè·³è¿‡å¯è§†åŒ–")
            return
        
        try:
            vis_dir = os.path.join(self.config.output_dir, "visualizations")
            os.makedirs(vis_dir, exist_ok=True)
            
            print("\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–æ–‡ä»¶...")
            
            # 1. ä¼˜åŒ–å†å²
            try:
                fig1 = vis.plot_optimization_history(self.study)
                fig1.write_html(f"{vis_dir}/optimization_history.html")
                print(f"   âœ… ä¼˜åŒ–å†å²: {vis_dir}/optimization_history.html")
            except Exception as e:
                print(f"   âŒ ä¼˜åŒ–å†å²ç”Ÿæˆå¤±è´¥: {e}")
            
            # 2. å‚æ•°é‡è¦æ€§
            try:
                if len(self.study.trials) >= 10:  # éœ€è¦è¶³å¤Ÿçš„è¯•éªŒæ•°æ®
                    fig2 = vis.plot_param_importances(self.study)
                    fig2.write_html(f"{vis_dir}/param_importances.html")
                    print(f"   âœ… å‚æ•°é‡è¦æ€§: {vis_dir}/param_importances.html")
            except Exception as e:
                print(f"   âŒ å‚æ•°é‡è¦æ€§ç”Ÿæˆå¤±è´¥: {e}")
            
            # 3. å¹³è¡Œåæ ‡å›¾
            try:
                if len(self.study.trials) >= 5:
                    fig3 = vis.plot_parallel_coordinate(self.study)
                    fig3.write_html(f"{vis_dir}/parallel_coordinate.html")
                    print(f"   âœ… å¹³è¡Œåæ ‡å›¾: {vis_dir}/parallel_coordinate.html")
            except Exception as e:
                print(f"   âŒ å¹³è¡Œåæ ‡å›¾ç”Ÿæˆå¤±è´¥: {e}")
            
            # 4. å‚æ•°å…³ç³»
            try:
                if len(self.study.trials) >= 10:
                    fig4 = vis.plot_slice(self.study)
                    fig4.write_html(f"{vis_dir}/param_slice.html")
                    print(f"   âœ… å‚æ•°åˆ‡ç‰‡å›¾: {vis_dir}/param_slice.html")
            except Exception as e:
                print(f"   âŒ å‚æ•°åˆ‡ç‰‡å›¾ç”Ÿæˆå¤±è´¥: {e}")
            
        except Exception as e:
            print(f"âš ï¸ å¯è§†åŒ–ç”Ÿæˆè¿‡ç¨‹å‡ºé”™: {e}")
    
    def print_system_info(self):
        """æ‰“å°ç³»ç»Ÿä¿¡æ¯"""
        print("ğŸ–¥ï¸  ç³»ç»Ÿä¿¡æ¯:")
        print(f"   æ“ä½œç³»ç»Ÿ: {os.name}")
        
        if hasattr(psutil, 'cpu_count'):
            print(f"   CPUæ ¸å¿ƒ: {psutil.cpu_count(logical=False)} ç‰©ç†, {psutil.cpu_count(logical=True)} é€»è¾‘")
            
        if hasattr(psutil, 'virtual_memory'):
            memory = psutil.virtual_memory()
            print(f"   å†…å­˜: {memory.total / 1e9:.1f}GB")
            
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
            print(f"   GPU: {gpu_name} ({gpu_memory:.1f}GB)")
    
    def save_results(self, optimization_time):
        """ä¿å­˜ä¼˜åŒ–ç»“æœ"""
        completed = [t for t in self.study.trials if t.state == optuna.trial.TrialState.COMPLETE]
        
        if not completed:
            print("\nâŒ æ²¡æœ‰æˆåŠŸå®Œæˆçš„è¯•éªŒ")
            return
        
        best_trial = self.study.best_trial
        
        # ä¿å­˜æ–‡æœ¬ç»“æœ
        results_file = os.path.join(self.config.output_dir, "best_hyperparameters.txt")
        with open(results_file, 'w', encoding='utf-8') as f:
            f.write(f"# è¶…å‚æ•°ä¼˜åŒ–ç»“æœ\n")
            f.write(f"# ä¼˜åŒ–æ—¶é—´: {datetime.datetime.now()}\n")
            f.write(f"# ç³»ç»Ÿ: {os.name}\n")
            if torch.cuda.is_available():
                f.write(f"# GPU: {torch.cuda.get_device_name(0)}\n")
            f.write(f"\næœ€ä½³Trial: #{best_trial.number}\n")
            f.write(f"æœ€ä½³éªŒè¯MAE: {self.study.best_value:.6f}\n")
            f.write(f"ä¼˜åŒ–è€—æ—¶: {optimization_time/3600:.2f}å°æ—¶\n\n")
            f.write("æœ€ä½³è¶…å‚æ•°:\n")
            for key, value in self.study.best_params.items():
                f.write(f"{key}: {value}\n")
        
        print(f"\nğŸ’¾ ç»“æœä¿å­˜è‡³: {results_file}")
        
        # ç”Ÿæˆè¿è¡Œè„šæœ¬
        script_file = os.path.join(self.config.output_dir, "run_best_config.sh")
        with open(script_file, 'w') as f:
            f.write("#!/bin/bash\n")
            f.write("# è¿è¡Œæœ€ä½³è¶…å‚æ•°é…ç½®\n\n")
            f.write("python main.py --config_file config.yml --task_type train \\\n")
            for key, value in self.study.best_params.items():
                f.write(f"  --{key} {value} \\\n")
            f.write("  --epochs 100\n")
        
        # è®¾ç½®æ‰§è¡Œæƒé™
        try:
            os.chmod(script_file, 0o755)
            print(f"ğŸ”§ è¿è¡Œè„šæœ¬: {script_file}")
        except:
            print(f"ğŸ”§ è¿è¡Œè„šæœ¬: {script_file} (è¯·æ‰‹åŠ¨è®¾ç½®æ‰§è¡Œæƒé™)")
    
    def run(self):
        """æ‰§è¡Œå®Œæ•´çš„è¶…å‚æ•°ä¼˜åŒ–æµç¨‹"""
        print("Starting Optuna hyperparameter optimization...")
        
        # æ‰“å°ç³»ç»Ÿä¿¡æ¯
        self.print_system_info()
        
        # è®¾ç½®å­˜å‚¨
        self.setup_storage()
        
        # åˆ›å»ºstudy
        self.create_study()
        
        # ä¼˜åŒ–é…ç½®ä¿¡æ¯
        print(f"\nğŸ¯ å¼€å§‹è¶…å‚æ•°ä¼˜åŒ–")
        print(f"ğŸ“Š è®¡åˆ’è¯•éªŒæ•°: {self.config.sweep_count}")
        print(f"ğŸ’¾ å­˜å‚¨æ¨¡å¼: {'SQLiteæ•°æ®åº“' if self.storage_name else 'å†…å­˜'}")
        if self.storage_name:
            print(f"ğŸ“ æ•°æ®åº“: {self.db_path}")
        print(f"ğŸ”§ æ¨èé…ç½®:")
        print(f"   - ä½¿ç”¨screenæˆ–tmuxè¿è¡Œé•¿æ—¶é—´ä»»åŠ¡")
        print(f"   - ç›‘æ§: nvidia-smi, htop")
        print(f"{'='*60}")
        
        optimization_start = time.time()
        
        try:
            # æ‰§è¡Œä¼˜åŒ–
            self.study.optimize(
                self.objective_function,
                n_trials=self.config.sweep_count,
                timeout=None,
                catch=(Exception,),
                show_progress_bar=True,
                gc_after_trial=True
            )
        except KeyboardInterrupt:
            print(f"\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­ä¼˜åŒ– (Ctrl+C)")
        except Exception as e:
            print(f"\nğŸ’¥ ä¼˜åŒ–è¿‡ç¨‹å‡ºé”™: {e}")
        
        # ç»“æœåˆ†æ
        optimization_time = time.time() - optimization_start
        
        print(f"\n{'='*60}")
        print(f"ğŸ‰ è¶…å‚æ•°ä¼˜åŒ–å®Œæˆ!")
        print(f"â±ï¸  æ€»è€—æ—¶: {optimization_time/3600:.1f}å°æ—¶")
        
        # ç»Ÿè®¡ä¿¡æ¯
        all_trials = self.study.trials
        completed = [t for t in all_trials if t.state == optuna.trial.TrialState.COMPLETE]
        pruned = [t for t in all_trials if t.state == optuna.trial.TrialState.PRUNED]
        failed = [t for t in all_trials if t.state == optuna.trial.TrialState.FAIL]
        
        print(f"\nğŸ“Š è¯•éªŒç»Ÿè®¡:")
        print(f"   æ€»è¯•éªŒ: {len(all_trials)}")
        print(f"   æˆåŠŸ: {len(completed)}")
        print(f"   å‰ªæ: {len(pruned)} (èŠ‚çœ {len(pruned)/(len(all_trials) or 1)*100:.1f}%)")
        print(f"   å¤±è´¥: {len(failed)}")
        
        # æœ€ä½³ç»“æœ
        if completed:
            best_trial = self.study.best_trial
            print(f"\nğŸ† æœ€ä½³ç»“æœ:")
            print(f"   Trial: #{best_trial.number}")
            print(f"   éªŒè¯MAE: {self.study.best_value:.6f}")
            print(f"   å‚æ•°:")
            for key, value in self.study.best_params.items():
                print(f"     {key}: {value}")
            
            # ä¿å­˜ç»“æœ
            self.save_results(optimization_time)
            
        else:
            print(f"\nâŒ æ²¡æœ‰æˆåŠŸå®Œæˆçš„è¯•éªŒ")
            print(f"ğŸ”§ è°ƒè¯•å»ºè®®:")
            print(f"   - æ£€æŸ¥æ•°æ®è·¯å¾„: {self.config.dataset_path}")
            print(f"   - æ£€æŸ¥GPUçŠ¶æ€: nvidia-smi")
            print(f"   - æ£€æŸ¥å†…å­˜: free -h")
            print(f"   - æ£€æŸ¥epochsè®¾ç½®: {self.config.epochs}")
        
        # ç”Ÿæˆå¯è§†åŒ–
        self.generate_visualizations()
        
        if self.storage_name and self.db_path and os.path.exists(self.db_path):
            print(f"ğŸ’¾ æ•°æ®åº“ä¿å­˜è‡³: {self.db_path}")
            print(f"ğŸ”§ æ•°æ®åº“æƒé™: {oct(os.stat(self.db_path).st_mode)[-3:]}")
        
        print(f"{'='*60}")
        
        return self.study